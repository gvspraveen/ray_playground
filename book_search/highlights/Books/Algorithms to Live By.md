# Algorithms to Live By

![](https://images-na.ssl-images-amazon.com/images/I/51FhJXhhK6L._SL200_.jpg)

### Metadata

- Author: Brian Christian, Tom Griffiths
- Full Title: Algorithms to Live By
- Category: #books

### Highlights

- Optimal stopping tells us when to look and when to leap. The explore/exploit tradeoff tells us how to find the balance between trying new things and enjoying our favorites. Sorting theory tells us how (and whether) to arrange our offices. Caching theory tells us how to fill our closets. Scheduling theory tells us how to fill our time. ([Location 82](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=82))
- tackling real-world tasks requires being comfortable with chance, trading off time with accuracy, and using approximations. ([Location 103](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=103))
- Any yardstick that provides full information on where an applicant stands relative to the population at large will change the solution from the Look-Then-Leap Rule to the Threshold Rule and will dramatically boost your chances of finding the single best applicant in the group. ([Location 341](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=341))
- Intuitively, we think that rational decision-making means exhaustively enumerating our options, weighing each one carefully, and then selecting the best. But in practice, when the clock—or the ticker—is ticking, few aspects of decision-making (or of thinking more generally) are as important as one: when to stop. ([Location 526](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=526))
    - **Tags:** #decision
- When balancing favorite experiences and new ones, nothing matters as much as the interval over which we plan to enjoy them. ([Location 595](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=595))
- A sobering property of trying new things is that the value of exploration, of finding a new favorite, can only go down over time, as the remaining opportunities to savor it dwindle. ([Location 602](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=602))
- So explore when you will have time to use the resulting knowledge, exploit when you’re ready to cash in. ([Location 606](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=606))
- To live in a restless world requires a certain restlessness in oneself. So long as things continue to change, you must never fully cease exploring. ([Location 965](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=965))
- Sorting something that you will never search is a complete waste; searching something you never sorted is merely inefficient. ([Location 1291](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=1291))
- “a man with one watch knows what time it is; a man with two watches is never sure. ([Location 2040](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2040))
- Priority inheritance. If a low-priority task is found to be blocking a high-priority resource, well, then all of a sudden that low-priority task should momentarily become the highest-priority ([Location 2089](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2089))
- It turns out, though, that even if you don’t know when tasks will begin, Earliest Due Date and Shortest Processing Time are still optimal strategies, able to guarantee you (on average) the best possible performance in the face of uncertainty. If assignments get tossed on your desk at unpredictable moments, the optimal strategy for minimizing maximum lateness is still the preemptive version of Earliest Due Date—switching to the job that just came up if it’s due sooner than the one you’re currently doing, and otherwise ignoring it. Similarly, the preemptive version of Shortest Processing Time—compare the time left to finish the current task to the time it would take to complete the new one—is still optimal for minimizing the sum of completion times. ([Location 2169](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2169))
- If we introduce a complexity penalty, then more complex models need to do not merely a better job but a significantly better job of explaining the data to justify their greater complexity. Computer scientists refer to this principle—using constraints that penalize models for their complexity—as Regularization. ([Location 2941](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2941))
- But it’s precisely because of the complexity of real life that a simple heuristic might in fact be the rational solution. ([Location 2972](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2972))
- “In contrast to the widely held view that less processing reduces accuracy,” they write, “the study of heuristics shows that less information, computation, and time can in fact improve accuracy.” A heuristic that favors simpler answers—with fewer factors, or less computation—offers precisely these “less is more” effects. ([Location 2985](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=2985))
- When it comes to culture, tradition plays the role of the evolutionary constraints. A bit of conservatism, a certain bias in favor of history, can buffer us against the boom-and-bust cycle of fads. That doesn’t mean we ought to ignore the latest data either, of course. Jump toward the bandwagon, by all means—but not necessarily on it. ([Location 3024](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=3024))
- The greater the uncertainty, the bigger the gap between what you can measure and what matters, the more you should watch out for overfitting—that is, the more you should prefer simplicity, and the earlier you should stop. ([Location 3057](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=3057))
    - **Tags:** #decision
- Unless we’re willing to spend eons striving for perfection every time we encounter a hitch, hard problems demand that instead of spinning our tires we imagine easier versions and tackle those first. When applied correctly, this is not just wishful thinking, not fantasy or idle daydreaming. It’s one of our best ways of making progress. ([Location 3324](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=3324))
    - **Tags:** #decision, #favorite
- Monte Carlo–informed computer scientist would propose a different approach: sampling. A close examination of random samples can be one of the most effective means of making sense of something too complex to be comprehended directly. When it comes to handling a qualitatively unmanageable problem, something so thorny and complicated that it can’t be digested whole—solitaire or atomic fission, primality testing or public policy—sampling offers one of the simplest, and also the best, ways of cutting through the difficulties. ([Location 3511](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=3511))
- This has emerged as one of the major insights of traditional game theory: the equilibrium for a set of players, all acting rationally in their own interest, may not be the outcome that is actually best for those players. ([Location 4347](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=4347))
- All employees want, in theory, to take as much vacation as possible. But they also all want to take just slightly less vacation than each other, to be perceived as more loyal, more committed, and more dedicated (hence more promotion-worthy). Everyone looks to the others for a baseline, and will take just slightly less than that. The Nash equilibrium of this game is zero. As the CEO of software company Travis CI, Mathias Meyer, writes, “People will hesitate to take a vacation as they don’t want to seem like that person who’s taking the most vacation days. It’s a race to the bottom.” ([Location 4401](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=4401))
- Whenever you find yourself on the side of the majority, it is time to pause and reflect. ([Location 4554](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=4554))
- In almost every domain we’ve considered, we have seen how the more real-world factors we include—whether it’s having incomplete information when interviewing job applicants, dealing with a changing world when trying to resolve the explore/exploit dilemma, or having certain tasks depend on others when we’re trying to get things done—the more likely we are to end up in a situation where finding the perfect solution takes unreasonably long. And indeed, people are almost always confronting what computer science regards as the hard cases. Up against such hard cases, effective algorithms make assumptions, show a bias toward simpler solutions, trade off the costs of error against the costs of delay, and take chances. These aren’t the concessions we make when we can’t be rational. They’re what being rational means. ([Location 4829](https://readwise.io/to_kindle?action=open&asin=B015CKNWJI&location=4829))
    - **Tags:** #favorite, #decision
