# Designing Data-Intensive Applications

![](https://images-na.ssl-images-amazon.com/images/I/514xvNk9rTL._SL200_.jpg)

### Metadata

- Author: Martin Kleppmann
- Full Title: Designing Data-Intensive Applications
- Category: #books

### Highlights

- user. It is impossible to reduce the probability of a fault to zero; therefore it is usually best to design fault-tolerance mechanisms that prevent faults from causing failures. ([Location 253](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=253))
- Scalability is the term we use to describe a system’s ability to cope with increased load. ([Location 361](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=361))
- Latency and response time are often used synonymously, but they are not the same. The response time is what the client sees: besides the actual time to process the request (the service time), it includes network delays and queueing delays. Latency is the duration that a request is waiting to be handled — during which it is latent, awaiting service [17]. ([Location 425](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=425))
    - **Tags:** #favorite
- People often talk of a dichotomy between scaling up (vertical scaling, moving to a more powerful machine) and scaling out (horizontal scaling, distributing the load across multiple smaller machines). Distributing load across multiple machines is also known as a shared-nothing architecture. ([Location 518](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=518))
- To this end, we will pay particular attention to three design principles for software systems: Operability Make it easy for operations teams to keep the system running smoothly. Simplicity Make it easy for new engineers to understand the system, by removing as ([Location 554](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=554))
- much complexity as possible from the system. (Note this is not the same as simplicity of the user interface.) Evolvability Make it easy for engineers to make changes to the system in the future, adapting it for unanticipated use cases as requirements change. Also known as extensibility, modifiability, or plasticity. As previously with reliability and scalability, there are no easy solutions for achieving these goals. Rather, we will try to think about systems with operability, simplicity, and evolvability in mind. Operability: ([Location 557](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=557))
- “good operations can often work around the limitations of bad (or incomplete) software, but good software cannot run reliably with bad operations” ([Location 565](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=565))
- The main arguments in favor of the document data model are schema flexibility, better performance due to locality, and that for some applications it is closer to the data structures used by the application. The relational model counters by providing better support for joins, and many-to-one and many-to-many relationships. ([Location 994](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=994))
    - **Tags:** #favorite
- However, if your application does use many-to-many relationships, the document model becomes less appealing. ([Location 1010](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=1010))
- MapReduce is neither a declarative query language nor a fully imperative query API, but somewhere in between: ([Location 1238](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=1238))
- Appending and segment merging are sequential write operations, which are generally much faster than random writes, especially on magnetic spinning-disk hard drives. To some extent sequential writes are also preferable on flash-based solid state drives ([Location 2024](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=2024))
- Backward compatibility Newer code can read data that was written by older code. Forward compatibility Older code can read data that was written by newer code. ([Location 2943](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=2943))
- Using a message broker has several advantages compared to direct RPC: It can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability. It can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost. It avoids the sender needing to know the IP address and port number of the recipient (which is particularly useful in a cloud deployment where virtual machines often come and go). It allows one message to be sent to several recipients. It logically decouples the sender from the recipient (the sender just publishes messages and doesn’t care who consumes them). ([Location 3552](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=3552))
    - **Tags:** #engineering, #favorite
- However, if the result is a bad experience for users, it’s important to design the system to provide a stronger guarantee, such as read-after-write. Pretending that replication is synchronous when in fact it is asynchronous is a recipe for problems down the line. ([Location 4255](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=4255))
    - **Tags:** #favorite, #engineering
- The simplest strategy for dealing with conflicts is to avoid them: if the application can ensure that all writes for a particular record go through the same leader, then conflicts cannot occur. Since many implementations of multi-leader replication handle conflicts quite poorly, avoiding conflicts is a frequently recommended approach [34]. ([Location 4378](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=4378))
- From an operational perspective, it’s important to monitor whether your databases are returning up-to-date results. Even if your application can tolerate stale reads, you need to be aware of the health of your replication. If it falls behind significantly, it should alert you so that you can investigate the cause ([Location 4636](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=4636))
- Databases with appropriately configured quorums can tolerate the failure of individual nodes without the need for failover. They can also tolerate individual nodes going slow, because requests don’t have to wait for all n nodes to respond — they can return when w or r nodes have responded. These characteristics make databases with leaderless replication appealing for use cases that require high availability and low latency, and that can tolerate occasional stale reads. ([Location 4655](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=4655))
    - **Tags:** #favorite
- Replication can serve several purposes: High availability Keeping the system running, even when one machine (or several machines, or an entire datacenter) goes down Disconnected operation Allowing an application to continue working when there is a network interruption Latency Placing data geographically close to users, so that users can interact with it faster Scalability Being able to handle a higher volume of reads than a single machine could handle, by performing reads on replicas ([Location 4874](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=4874))
- If the partitioning is unfair, so that some partitions have more data or queries than others, we call it skewed. The presence of skew makes partitioning much less effective. In an extreme case, all the load could end up on one partition, ([Location 5114](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=5114))
- Fixed number of partitions Fortunately, there is a fairly simple solution: create many more partitions than there are nodes, and assign several partitions to each node. For example, a database running on a cluster of 10 nodes may be split into 1,000 partitions from the outset so that approximately 100 partitions are assigned to each node. Now, if a node is added to the cluster, the new node can steal a few partitions from every existing node until partitions are fairly distributed once again. This process is illustrated in Figure 6-6. If a node is removed from the cluster, the same happens in reverse. Only entire partitions are moved between nodes. The number of partitions does not change, nor does the assignment of keys to partitions. The only thing that changes is the assignment of partitions to nodes. This change of assignment is not immediate — it takes some time to transfer a large amount of data over the network — so the old assignment of partitions is used for any reads and writes that happen ([Location 5341](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=5341))
- Atomicity If an error occurs halfway through a sequence of writes, the transaction should be aborted, and the writes made up to that point should be discarded. In other words, the database saves you from having to worry about partial failure, by giving an all-or-nothing guarantee. Isolation Concurrently running transactions shouldn’t interfere with each other. For example, if one transaction makes several writes, then another transaction should see either all or none of those writes, but not some subset. ([Location 5789](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=5789))
- In databases that don’t provide transactions, you sometimes find an atomic compare-and-set operation (previously mentioned in “Single-object writes”). The purpose of this operation is to avoid lost updates by allowing an update to happen only if the value has not changed since you last read it. If the current value does not match what you previously read, the update has no effect, and the read-modify-write cycle must be retried. For example, to prevent two users concurrently updating the same wiki page, you might try something like this, expecting the update to occur only if the content of the page hasn’t changed since the user started editing it: -- This may or may not be safe, depending on the database implementation UPDATE wiki_pages SET content = 'new content'   WHERE id = 1234 AND content = 'old content'; ([Location 6222](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=6222))
    - **Tags:** #engineering
- In 2PL, writers don’t just block other writers; they also block readers and vice versa. Snapshot isolation has the mantra readers never block writers, and writers never block readers (see “Implementing snapshot isolation”), which captures this key difference between snapshot isolation and two-phase locking. On the other hand, because 2PL provides serializability, it protects against all the race conditions discussed earlier, including lost updates and write skew. ([Location 6537](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=6537))
- Tools like ZooKeeper play an important role in providing an “outsourced” consensus, failure detection, and membership service that applications can use. ([Location 9702](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=9702))
- The distinguishing feature of a batch processing job is that it reads some input data and produces some output data, without modifying the input — in other words, the output is derived from the input. Crucially, the input data is bounded: it has a known, fixed size (for example, it consists of a set of log files at some point in time, or a snapshot of a database’s contents). Because it is bounded, a job knows when it has finished reading the entire input, and so a job eventually completes when it is done. In the next chapter, we will turn to stream processing, in which the input is unbounded — that is, you still have a job, but its inputs are never-ending streams of data. In this case, a job is never complete, because at any time there may still be more work coming in. We shall see that stream and batch processing are similar in some respects, but the assumption of unbounded streams also ([Location 11305](https://readwise.io/to_kindle?action=open&asin=B06XPJML5D&location=11305))
